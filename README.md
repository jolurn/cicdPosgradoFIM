<div align="center">

# ğŸ“ ETL Pipeline for FIM Postgraduate Student Payments System
### Arquitectura Medallion en Azure Databricks

![My Skills](https://skillicons.dev/icons?i=html,databricks,python,spark,,git,github,aws,azure,flask,tensorflow,vscode)

*Pipeline ETL para el procesamiento y anÃ¡lisis de pagos de estudiantes del Posgrado FIM-UNI con arquitectura Medallion y despliegue continuo*

</div>

---

## ğŸ¯ DescripciÃ³n

Pipeline ETL de nivel empresarial para el procesamiento de transacciones financieras acadÃ©micas del Posgrado de la Facultad de IngenierÃ­a MecÃ¡nica de la Universidad Nacional de IngenierÃ­a (FIM-UNI). Implementa la Arquitectura Medallion (Bronze-Silver-Gold) en Azure Databricks con CI/CD automatizado y Delta Lake para garantizar consistencia ACID y trazabilidad completa.

### âœ¨ CaracterÃ­sticas Principales

- ğŸ”„ **ETL Automatizado** - Pipeline completo con despliegue automÃ¡tico via GitHub Actions
- ğŸ—ï¸ **Arquitectura Medallion** - SeparaciÃ³n clara de capas Bronze â†’ Silver â†’ Gold
- ğŸ“Š **Modelo Dimensional** - Star Schema optimizado para anÃ¡lisis de negocio
- ğŸš€ **CI/CD Integrado** - Deploy automÃ¡tico en cada push a master
- ğŸ“ˆ **Databricks Dashboards** - VisualizaciÃ³n
- âš¡ **Delta Lake** - ACID transactions y time travel capabilities
- ğŸ”” **Monitoreo** - Notificaciones automÃ¡ticas y logs detallados

---

## ğŸ›ï¸ Arquitectura

### Flujo de Datos

```
ğŸ“ Datos Fuente (Sistemas FIM-UNI)
    â†“
ğŸ”§ 1_Preparacion_Ambiente_FIM
    â†“
ğŸ—‘ï¸ 0_Drop_All_FIM (Limpieza inicial)
    â†“
ğŸ¥‰ 2_DDLs_Bronze_FIM (Esquemas Bronze)
    â†“
ğŸ¥ˆ 3_DDLs_Silver_FIM (Esquemas Silver)
    â†“
ğŸ¥‡ 4_DDLs_Golden_FIM (Esquemas Gold)
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
ğŸ“Š 5A_Ingesta_Dimensiones_1_FIM    ğŸ“Š 5B_Ingesta_Dimensiones_2_FIM
    â”‚                                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
ğŸ‘¥ 5C_Ingesta_Usuarios_FIM
                â†“
ğŸ“ 5D_Ingesta_Alumno_FIM
                â†“
ğŸ’° 5E_Ingesta_Hechos_FIM (Transacciones de pagos)
                â†“
ğŸ”„ 6_Transform_Bronze_Silver_FIM (ETL principal)
                â†“
ğŸ“ˆ 7_Agregacion_Silver_Golden_FIM (KPI's acadÃ©micos)
                â†“
ğŸ” 8_Grants_FIM (GestiÃ³n de permisos)
                â†“
ğŸ¤ 9_DeltaSharing_FIM (Compartir datos)
    â†“
ğŸ“Š Power BI Dashboards (VisualizaciÃ³n ejecutiva)
```

![Texto descriptivo](Arquitectura.png)


### ğŸ“¦ Capas del Pipeline

<table>
<tr>
<td width="33%" valign="top">

#### ğŸ¥‰ Bronze Layer
**PropÃ³sito**: Zona de aterrizaje para datos crudos del sistema acadÃ©mico

**Tablas Principales**: 
- `alumnos_bronze - Datos bÃ¡sicos de estudiantes` 
- `maestrias_bronze - Programas de posgrado y especialidades` 
- `conceptos_pago_bronze - Tipos de pagos acadÃ©micos`
- `reportes_economicos_bronze - Transacciones financieras` 
- `periodos_bronze - Periodos acadÃ©micos`

**CaracterÃ­sticas**:
- âœ… Datos extraÃ­dos directamente de pfimapp_*.csv
- âœ… Timestamp automÃ¡tico de ingesta
- âœ… PreservaciÃ³n histÃ³rica completa
- âœ… Sin validaciones ni transformaciones
- âœ… Estructura idÃ©ntica a los archivos origen

</td>
<td width="33%" valign="top">

#### ğŸ¥ˆ Silver Layer
**PropÃ³sito**: Modelo dimensional para anÃ¡lisis acadÃ©mico-financiero

**Tablas Principales**:
- `dim_alumno - InformaciÃ³n completa de estudiantes`
- `dim_maestria - Programas y especialidades con atributos`
- `dim_periodo - DimensiÃ³n temporal acadÃ©mica`
- `dim_concepto_pago - CatÃ¡logo de conceptos de pago`
- `fact_pagos - Hechos de transacciones financieras`
- `fact_estado_academico - SituaciÃ³n acadÃ©mica por alumno`

**CaracterÃ­sticas**:
- âœ… Star Schema optimizado para consultas
- âœ… ValidaciÃ³n completa de datos acadÃ©micos
- âœ… Limpieza de duplicados e inconsistencias
- âœ… NormalizaciÃ³n de formatos y estÃ¡ndares
- âœ… Relaciones acadÃ©micas bien definidas

</td>
<td width="33%" valign="top">

#### ğŸ¥‡ Gold Layer
**PropÃ³sito**: Vistas analÃ­ticas listas para toma de decisiones

**Tablas/Vistas AnalÃ­ticas**:
- kpi_pagos_por_maestria - Ingresos totales agrupados por programa y periodo
- kpi_estado_financiero_alumnos - SituaciÃ³n de pagos por estudiante
- kpi_morosidad_academica - AnÃ¡lisis de deudas por cohorte
- kpi_distribucion_conceptos - Conceptos de pago mÃ¡s frecuentes
- kpi_proyeccion_ingresos - Forecast financiero por trimestre

**CaracterÃ­sticas**:
- âœ… Agregaciones pre-calculadas para BI
- âœ… Optimizado para Power BI con DirectQuery
- âœ… Actualizaciones incrementales automÃ¡ticas
- âœ… KPI's acadÃ©micos pre-definidos
- âœ… MÃ¡ximo performance para dashboards ejecutivos

</td>
</tr>
</table>

---

## ğŸ“ Estructura del Proyecto

```
ETL_PosgradoFIM/
â”‚
â”œâ”€â”€ ğŸ“‚ .github/workflows/
â”‚   â””â”€â”€ ğŸ“„ deploy-notebook.yml          # Pipeline CI/CD para Databricks
â”‚
â”œâ”€â”€ ğŸ“‚ Certificaciones/                 # Certificaciones obtenidas
â”‚   â”œâ”€â”€ ğŸ“„ Databricks Fundamentals.pdf
â”‚   â”œâ”€â”€ ğŸ“„ Databricks Generative AI Fundamentals.pdf
â”‚   â”œâ”€â”€ ğŸ“„ Databricks Platform Administrator.pdf
â”‚   â”œâ”€â”€ ğŸ“Š Dashboard.pdf                # Export del dashboard
â”‚   â””â”€â”€ ğŸ–¼ï¸ Dashboard.png               # Imagen del dashboard
â”‚
â”œâ”€â”€ ğŸ“‚ Procesos/                        # Notebooks de procesamiento ETL
â”‚   â”œâ”€â”€ ğŸ“ 5A_Ingesta_Dimensiones_1_FIM.py      # Ingestion dimensiones 1
â”‚   â”œâ”€â”€ ğŸ“ 5B_Ingesta_Dimensiones_2_FIM.py      # Ingestion dimensiones 2
â”‚   â”œâ”€â”€ ğŸ‘¥ 5C_Ingesta_Usuarios_FIM.py          # Ingestion usuarios
â”‚   â”œâ”€â”€ ğŸ“ 5D_Ingesta_Alumno_FIM.py            # Ingestion alumnos
â”‚   â”œâ”€â”€ ğŸ’° 5E_Ingesta_Hechos_FIM.py            # Ingestion transacciones
â”‚   â”œâ”€â”€ ğŸ”„ 6_Transform_Bronze_Silver_FIM.py    # TransformaciÃ³n Bronzeâ†’Silver
â”‚   â””â”€â”€ ğŸ“ˆ 7_Agregacion_Silver_Golden_FIM.py   # AgregaciÃ³n Silverâ†’Gold
â”‚
â”œâ”€â”€ ğŸ“‚ Reversion/                       # Scripts de reversiÃ³n/limpieza
â”‚   â””â”€â”€ ğŸ§¹ 0_Drop_All_FIM.py            # Limpieza completa de datos
â”‚
â”œâ”€â”€ ğŸ“‚ Scripts/                         # Scripts de preparaciÃ³n y DDLs
â”‚   â”œâ”€â”€ âš™ï¸ 1_Preparacion_Ambiente_FIM.py      # PreparaciÃ³n del ambiente
â”‚   â”œâ”€â”€ ğŸ¥‰ 2_DDLs_Bronze_FIM.py               # DDLs para capa Bronze
â”‚   â”œâ”€â”€ ğŸ¥ˆ 3_DDLs_Silver_FIM.py               # DDLs para capa Silver
â”‚   â””â”€â”€ ğŸ¥‡ 4_DDLs_Golden_FIM.py               # DDLs para capa Gold
â”‚
â”œâ”€â”€ ğŸ“‚ Seguridad/                       # GestiÃ³n de seguridad y permisos
â”‚   â”œâ”€â”€ ğŸ” 8_Grants_FIM.py              # AsignaciÃ³n de permisos
â”‚   â””â”€â”€ ğŸ“„ README.md                    # DocumentaciÃ³n de seguridad
â”‚
â””â”€â”€ ğŸ“„ README.md                        # DocumentaciÃ³n principal del proyecto
```

---

## ğŸ› ï¸ TecnologÃ­as

<div align="center">

| TecnologÃ­a | PropÃ³sito |
|:----------:|:----------|
| ![Databricks](https://img.shields.io/badge/Azure_Databricks-FF3621?style=flat-square&logo=databricks&logoColor=white) | Motor de procesamiento distribuido Spark |
| ![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=flat-square&logo=delta&logoColor=white) | Storage layer con ACID transactions |
| ![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) | Framework de transformaciÃ³n de datos |
| ![ADLS](https://img.shields.io/badge/ADLS_Gen2-0078D4?style=flat-square&logo=microsoft-azure&logoColor=white) | Data Lake para almacenamiento persistente |
| ![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=flat-square&logo=github-actions&logoColor=white) | AutomatizaciÃ³n CI/CD |
| ![Databricks Dashboards](https://img.shields.io/badge/Databricks Dashboards-F2C81?style=for-the-badge&logo=databricks&logoColor=black) |  VisualizaciÃ³n |

</div>

---

## âš™ï¸ Requisitos Previos

1. Archivos Fuente del Sistema FIMAPP
Acceso a los 12 archivos CSV del sistema acadÃ©mico:

- âœ… pfimapp_alumno.csv - Datos de estudiantes

- âœ… pfimapp_user.csv - Usuarios del sistema

- âœ… pfimapp_maestria.csv - Programas de posgrado

- âœ… pfimapp_conceptopago.csv - Conceptos de pago

- âœ… pfimapp_reporteeconomico.csv - Reportes econÃ³micos

- âœ… pfimapp_reporteecoconceptopago.csv - Detalles de pagos

- âœ… pfimapp_periodo.csv - Periodos acadÃ©micos

- âœ… pfimapp_sede.csv - Sedes de estudio

- âœ… pfimapp_estadoacademico.csv - Estado acadÃ©mico

- âœ… pfimapp_estadoboletap.csv - Estado de boletas

- âœ… pfimapp_estadocivil.csv - Estado civil

- âœ… pfimapp_tipodocumento.csv - Tipos de documento

2. Infraestructura Azure
- â˜ï¸ Cuenta de Azure con suscripciÃ³n activa

- ğŸ¢ Azure Databricks Workspace configurado

- ğŸ’¾ Azure Data Lake Storage Gen2:

Storage Account: adlsnolascodev2411

Contenedores: fim-bronze, fim-silver, fim-gold

- ğŸ” Service Principal con permisos de Contributor en ADLS

3. ConfiguraciÃ³n Databricks
- ğŸ–¥ï¸ Cluster activo: ClusterSD (Standard_D4s_v3, Single Node)

- ğŸ“ Unity Catalog: catalog_fim configurado

- ğŸ“‚ Esquemas: bronze, silver, gold creados

- ğŸ”‘ Access Tokens: Generados para API de Databricks

- âš™ï¸ Workspace paths: /proyecto_posgrado/ configurado

4. IntegraciÃ³n CI/CD con GitHub
- ğŸ™ Cuenta de GitHub con repositorio del proyecto

- âš¡ GitHub Actions habilitado en el repositorio

- ğŸ” Secrets configurados en GitHub Settings:

DATABRICKS_ORIGIN_HOST

DATABRICKS_ORIGIN_TOKEN

DATABRICKS_DEST_HOST

DATABRICKS_DEST_TOKEN

- ğŸ‘¨â€ğŸ’¼ Permisos de administrador en el repositorio

5. Herramientas de Desarrollo
- ğŸ’» Python 3.8+ instalado localmente

- ğŸ”§ Databricks CLI configurado y autenticado

- ğŸ“¦ LibrerÃ­as esenciales:

databricks-cli>=0.17.0

requests>=2.28.0

jq (para procesamiento JSON en CI/CD)

- ğŸ–¥ï¸ Terminal bash (Git Bash en Windows, Terminal en Mac/Linux)

6. VisualizaciÃ³n con Power BI (Recomendado)
- ğŸ“Š Power BI Desktop (versiÃ³n actual)

- ğŸ”— Conector Databricks instalado

- ğŸ”„ DirectQuery configurado para conexiÃ³n en vivo

- ğŸ“ˆ Licencia Power BI Pro/PPU para publicaciÃ³n de dashboards

- ğŸ¨ Workspace Power BI para compartir reportes

7. Permisos y Seguridad
- ğŸ‘¨â€ğŸ’¼ Rol Admin en Databricks Workspace

- ğŸ“‹ Storage Blob Data Contributor en ADLS Gen2

- ğŸ”„ Acceso a APIs: jobs/run, workspace/import, clusters/list

- ğŸ“§ Email configurado para notificaciones de workflow

- ğŸ” Secret Scope configurado en Databricks para credenciales

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el Repositorio

```bash
https://github.com/jolurn/cicdPosgradoFIM.git
cd project-databricks
```

### 2ï¸âƒ£ Configurar Databricks Token

1. Ir a Databricks Workspace
2. **User Settings** â†’ **Developer** â†’ **Access Tokens**
3. Click en **Generate New Token**
4. Configurar:
   - **Comment**: `GitHub CI/CD`
   - **Lifetime**: `90 days`
5. âš ï¸ Copiar y guardar el token

### 3ï¸âƒ£ Configurar GitHub Secrets

En tu repositorio: **Settings** â†’ **Secrets and variables** â†’ **Actions**

| Secret Name | Valor Ejemplo |
|------------|---------------|
| `DATABRICKS_HOST` | `https://adb-xxxxx.azuredatabricks.net` |
| `DATABRICKS_TOKEN` | `dapi_xxxxxxxxxxxxxxxx` |

### 4ï¸âƒ£ Verificar Storage Configuration

```python
storage_path = "abfss://raw@adlsnolascodev2411.dfs.core.windows.net"
```

<div align="center">

âœ… **Â¡ConfiguraciÃ³n completa!**

</div>

---

## ğŸ’» Uso

### ğŸ”„ Despliegue AutomÃ¡tico (Recomendado)

```bash
git add .
git commit -m "âœ¨ feat: mejoras en pipeline"
git push origin master
```

**GitHub Actions ejecutarÃ¡**:
- ğŸ“¤ Deploy de 14 notebooks a `/proyecto_posgrado/`
- ğŸ”§ CreaciÃ³n del workflow `WF_ETL_PFIM`
- â–¶ï¸ EjecuciÃ³n completa:  Bronze â†’ Silver â†’ Gold
- ğŸ“§ Notificaciones de resultados

### ğŸ–±ï¸ Despliegue Manual desde GitHub

1. Ir al tab **Actions** en GitHub
2. Seleccionar **Dynamic Databricks Notebook Deploy**
3. Click en **Run workflow**
4. Seleccionar rama `main`
5. Click en **Run workflow**

### ğŸ”§ EjecuciÃ³n Local en Databricks

Navegar a `proyecto_posgrado` y ejecutar en orden:

```
ğŸ¯ FASE 1: PREPARACIÃ“N
- 1_Preparacion_Ambiente_FIM.py    â†’ ConfiguraciÃ³n inicial del entorno
- 0_Drop_All_FIM.py                â†’ Limpieza de datos anteriores

ğŸ—ï¸ FASE 2: CREACIÃ“N DE ESQUEMAS  
- 2_DDLs_Bronze_FIM.py             â†’ Esquemas para datos crudos (Bronze)
- 3_DDLs_Silver_FIM.py             â†’ Esquemas para datos limpios (Silver)
- 4_DDLs_Golden_FIM.py             â†’ Esquemas para vistas analÃ­ticas (Gold)

ğŸ“¥ FASE 3: INGESTA DE DATOS ACADÃ‰MICOS
- 5A_Ingesta_Dimensiones_1_FIM.py  â†’ Dimensiones bÃ¡sicas del sistema
- 5B_Ingesta_Dimensiones_2_FIM.py  â†’ Dimensiones adicionales acadÃ©micas
- 5C_Ingesta_Usuarios_FIM.py       â†’ Datos de usuarios del sistema FIMAPP
- 5D_Ingesta_Alumno_FIM.py         â†’ InformaciÃ³n completa de estudiantes
- 5E_Ingesta_Hechos_FIM.py         â†’ Transacciones financieras y pagos

ğŸ”„ FASE 4: TRANSFORMACIÃ“N Y ANÃLISIS
- 6_Transform_Bronze_Silver_FIM.py â†’ ETL principal: Bronze â†’ Silver
- 7_Agregacion_Silver_Golden_FIM.py â†’ GeneraciÃ³n de KPI's: Silver â†’ Gold

ğŸ” FASE 5: GESTIÃ“N Y SEGURIDAD
- 8_Grants_FIM.py                  â†’ AsignaciÃ³n de permisos de acceso
- 9_DeltaSharing_FIM.py            â†’ Compartir datos con Power BI
```

---


## ğŸ”„ CI/CD

### Pipeline de GitHub Actions

```yaml
Workflow: Dynamic Databricks Notebook Deploy
â”œâ”€â”€ Trigger: Push a rama main
â”œâ”€â”€ Paso 1: Exportar 14 notebooks desde workspace origen
â”œâ”€â”€ Paso 2: Desplegar notebooks a /proyecto_posgrado/
â”œâ”€â”€ Paso 3: Eliminar workflow WF_ADB anterior (si existe)
â”œâ”€â”€ Paso 4: Buscar cluster ClusterSD configurado
â”œâ”€â”€ Paso 5: Crear nuevo workflow WF_POSGRADO con 14 tareas
â”œâ”€â”€ Paso 6: Validar configuraciÃ³n del workflow creado
â”œâ”€â”€ Paso 7: Ejecutar pipeline ETL completo automÃ¡ticamente
â”œâ”€â”€ Paso 8: Monitorear ejecuciÃ³n en tiempo real (10 min timeout)
â””â”€â”€ Paso 9: Limpiar archivos temporales y notificar resultados
```

### ğŸ”„  Workflow Databricks
![Texto descriptivo](CICD_ETL_POSGRADO_FIM_UNI.png)


---

## ğŸ“ˆ Dashboards
![Texto descriptivo](/Dashboard/Dashboard.png)

## ğŸ” Monitoreo

### En Databricks

**Workflows**:
- Ir a **Workflows** en el menÃº lateral
- Buscar `WF_ETL_PFIM`
- Ver historial de ejecuciones

**Logs por Tarea**:
- Click en una ejecuciÃ³n especÃ­fica
- Click en cada tarea para ver logs detallados
- Revisar stdout/stderr en caso de errores

### En GitHub Actions

- Tab **Actions** del repositorio
- Ver historial de workflows
- Click en ejecuciÃ³n especÃ­fica para detalles
- Revisar logs de cada step

---

## ğŸ‘¤ Autor

<div align="center">

### Jorge Luis Ramos Nolasco

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/jramosn/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)]([https://github.com/guaru](https://github.com/jolurn))
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](jolurn7@gmail.com)

**Data Engineering** | **Azure Databricks** | **Delta Lake** | **CI/CD**

</div>

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

<div align="center">

**Proyecto**: Data Engineering - Arquitectura Medallion  
**TecnologÃ­a**: Azure Databricks + Delta Lake + CI/CD  
**Ãšltima actualizaciÃ³n**: 2025


</div>
